import json
import pandas as pd
import requests
import streamlit as st

# ============ CONFIGURA√á√ÉO ============
OLLAMA_URL = "http://localhost:11434/api/generate"
MODELO = "gpt-oss:20b"

# ============ CARREGAR DADOS ============
perfil = json.load(open('./Data/perfil_cliente.json'))
transacoes = pd.read_csv('./Data/transacoes.csv')
historico = pd.read_csv('./Data/historico_atendimento.csv')
produtos = json.load(open('./Data/programas_consultoria.json'))

# ============ MONTAR CONTEXTO ============
contexto = f"""
CLIENTE: {perfil['nome']}, {perfil['idade']} anos, perfil {perfil['ramo_de_atividade']}
OBJETIVO: {perfil['objetivo_principal']}


TRANSA√á√ïES RECENTES:
{transacoes.to_string(index=False)}

ATENDIMENTOS ANTERIORES:
{historico.to_string(index=False)}

PRODUTOS DISPON√çVEIS:
{json.dumps(produtos, indent=2, ensure_ascii=False)}
"""

# ============ SYSTEM PROMPT (Defini√ß√£o da Vari√°vel) ============
# ============ SYSTEM PROMPT ============
# O texto PRECISA estar entre aspas triplas para o Python entender que √© apenas texto
SYSTEM_PROMPT = '''
Voc√™ √© o Edem, um consultor de controladoria e finan√ßas corporativas.

OBJETIVO:
Analisar os dados enviados do cliente, ponderando diagn√≥stico e objetivo, a fim de fazer recomenda√ß√µes de melhoria.

REGRAS:
- NUNCA recomende investimentos espec√≠ficos, apenas explique como funcionam;
- JAMAIS responda a perguntas fora do tema ensino de consultoria em gest√£o financeira;
- Use os dados fornecidos para dar exemplos personalizados;
- Linguagem simples, como se explicasse para um amigo;
- Sempre pergunte se o cliente entendeu;
- Responda de forma sucinta e direta, com no m√°ximo 3 par√°grafos.
'''''

# ============ MONTAR CONTEXTO ============
contexto = f'''
CLIENTE: {perfil.get('nome', 'N/A')}, {perfil.get('idade', 'N/A')} anos
RAMO: {perfil.get('ramo_de_atividade', 'N/A')}
OBJETIVO: {perfil.get('objetivo_principal', 'N/A')}

TRANSA√á√ïES RECENTES:
{transacoes.head(10).to_string(index=False)}

ATENDIMENTOS ANTERIORES:
{historico.head(5).to_string(index=False)}

PRODUTOS DISPON√çVEIS:
{json.dumps(produtos, indent=2, ensure_ascii=False)}
'''

# ============ CHAMAR OLLAMA ============
def perguntar(msg):
    prompt = f"{SYSTEM_PROMPT}\n\nCONTEXTO DO CLIENTE:\n{contexto}\n\nPergunta: {msg}"
    
    try:
        r = requests.post(OLLAMA_URL, json={"model": MODELO, "prompt": prompt, "stream": False})
        dados = r.json()
        
        # Verificando se 'response' realmente existe antes de acessar
        if 'response' in dados:
            return dados['response']
        else:
            # Se der erro, o Ollama costuma enviar o motivo no campo 'error'
            erro_ollama = dados.get('error', 'Resposta desconhecida')
            return f"O Ollama respondeu com um erro: {erro_ollama}"
            
    except Exception as e:
        return f"Erro t√©cnico na chamada: {e}"

# ============ INTERFACE STREAMLIT ============
st.title("üéì Edem, o Consultor Virtual")

if pergunta := st.chat_input("Sua d√∫vida sobre finan√ßas..."):
    st.chat_message("user").write(pergunta)
    with st.spinner("..."):
        resposta = perguntar(pergunta)
        st.chat_message("assistant").write(resposta)